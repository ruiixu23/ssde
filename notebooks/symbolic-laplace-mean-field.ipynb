{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load init.py\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "# Enable module import from the parent directory from notebooks\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import time\n",
    "\n",
    "import matplotlib as mpl\n",
    "# Select plotting backend\n",
    "mpl.use('nbAgg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Customize plotting\n",
    "plt.style.use('seaborn-paper')\n",
    "plt.rcParams['axes.labelsize'] = 11.0\n",
    "plt.rcParams['axes.titlesize'] = 12.0\n",
    "plt.rcParams['errorbar.capsize'] = 3.0\n",
    "plt.rcParams['figure.dpi'] = 72.0\n",
    "plt.rcParams['figure.titlesize'] = 12.0\n",
    "plt.rcParams['legend.fontsize'] = 10.\n",
    "plt.rcParams['lines.linewidth'] = 1.\n",
    "plt.rcParams['xtick.labelsize'] = 11.0\n",
    "plt.rcParams['ytick.labelsize'] = 11.0\n",
    "\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "sp.init_printing(euler=True, use_latex=True)\n",
    "\n",
    "from IPython import display\n",
    "from scipy import io, optimize\n",
    "from sklearn import metrics\n",
    "\n",
    "import core\n",
    "import dynamicals\n",
    "import kernels\n",
    "import numericals\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dynamical = dynamicals.LotkaVolterra()\n",
    "\n",
    "spl_t_0, spl_t_T, spl_freq = 0, 2, 100\n",
    "obs_t_0, obs_t_T, obs_freq = 0, 2, 10\n",
    "est_t_0, est_t_T, est_freq = 0, 2, 10\n",
    "spl_tps, obs_tps, obs_t_indices, est_tps, est_t_indices = utils.create_time(\n",
    "    spl_t_0, spl_t_T, spl_freq, obs_t_0, obs_t_T, obs_freq, est_t_0, est_t_T, est_freq)\n",
    "X_0 = np.array([5., 3.]) \n",
    "theta = np.array([2., 1., 1., 4.]) \n",
    "rho_2 = None\n",
    "phi = [\n",
    "    # (Kernal name, Kernal parameters)\n",
    "    ('rbf', np.sqrt([2.5, 0.02])),\n",
    "    ('rbf', np.sqrt([2.5, 0.02]))\n",
    "]\n",
    "sigma_2 = np.array([0.1, 0.1]) \n",
    "delta = np.full(dynamical.num_x, True)\n",
    "gamma = np.array([5e-3, 5e-3]) \n",
    "\n",
    "opt_method = 'Newton-CG'\n",
    "opt_tol = 1e-6\n",
    "max_init_iter = None\n",
    "max_iter = 2000\n",
    "\n",
    "plotting_enabled = True\n",
    "plotting_freq = 50\n",
    "plotting_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dynamical = dynamicals.ProteinSignallingTransduction() \n",
    "\n",
    "spl_t_0, spl_t_T, spl_freq = 0, 100, 20\n",
    "obs_t_0, obs_t_T, obs_freq = 0, 100, 20\n",
    "est_t_0, est_t_T, est_freq = 0, 100, 20\n",
    "spl_tps, obs_tps, obs_t_indices, est_tps, est_t_indices = utils.create_time(\n",
    "    spl_t_0, spl_t_T, spl_freq, obs_t_0, obs_t_T, obs_freq, est_t_0, est_t_T, est_freq)\n",
    "t_indices = np.array([0, 1, 2, 4, 5, 7, 10, 15, 20, 30, 40, 50, 60, 80, 100]) * spl_freq\n",
    "obs_tps = obs_tps[t_indices]\n",
    "obs_t_indices = obs_t_indices[t_indices]\n",
    "est_tps = est_tps[t_indices]\n",
    "est_t_indices = est_t_indices[t_indices]\n",
    "X_0 = np.array([1., 0., 1., 0., 0.]) \n",
    "theta = np.array([0.07, 0.6, 0.05, 0.3, 0.017, 3.]) \n",
    "rho_2 = None\n",
    "sigma_2 = np.full(dynamical.num_x, 1e-2) \n",
    "delta = np.full(dynamical.num_x, True) \n",
    "# gamma = np.full(dynamical.num_x, 5e-3) \n",
    "gamma = np.array([1e-4, 1e-4, 2e-6, 1e-5, 5e-2])\n",
    "phi = [\n",
    "    # (Kernal name, Kernal parameters)\n",
    "    ('sigmoid', np.array([1., .4, 15.])),\n",
    "    ('sigmoid', np.array([.18, .6, 25.])),\n",
    "    ('sigmoid', np.array([.84, 3., 3.1])),\n",
    "    ('sigmoid', np.array([.62, 2., 2.1])),\n",
    "    ('sigmoid', np.array([.84, 3., 2.9])),\n",
    "]\n",
    "\n",
    "opt_method = 'Newton-CG'\n",
    "opt_tol = 1e-6\n",
    "max_init_iter = None\n",
    "max_iter = 2000\n",
    "\n",
    "plotting_enabled = True\n",
    "plotting_freq = 50\n",
    "plotting_config = {\n",
    "    'x': {\n",
    "        'xlim': (0, 100),\n",
    "        'ylim': (0., 1.2)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spl_X = dynamical.generate_sample_path(theta, rho_2, X_0, spl_tps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "obs_Y = utils.collect_observations(spl_X, obs_t_indices, sigma_2, [0, None])\n",
    "\n",
    "mu, Sigma, inv_Sigma, m, inv_Lambda, Lambda = core.init_with_gaussian_processes(dynamical, \n",
    "                                                                                obs_Y, obs_tps, \n",
    "                                                                                est_tps,\n",
    "                                                                                phi, sigma_2, delta, gamma,\n",
    "                                                                                plotting_enabled)\n",
    "\n",
    "utils.plot_states(dynamical, spl_X, spl_tps, obs_Y, obs_tps, delta, mu, est_tps, plotting_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_x = dynamical.num_x\n",
    "num_theta = dynamical.num_theta\n",
    "num_est_t = est_tps.size\n",
    "\n",
    "X_sym = sp.Matrix(\n",
    "    list(sp.symbols('{}[(:{})][(:{})]'.format(dynamical.x_label, num_x, num_est_t), real=True))\n",
    ").reshape(num_x, num_est_t)\n",
    "\n",
    "theta_sym = sp.Matrix(\n",
    "    dynamical.theta\n",
    ")\n",
    "\n",
    "F_sym = sp.Matrix.hstack(*[\n",
    "    dynamical.F.xreplace(dict(zip(dynamical.x, X_sym.col(t))))\n",
    "    for t in range(num_est_t)\n",
    "])\n",
    "\n",
    "mx_sym = sp.Matrix.hstack(*[\n",
    "    sp.Matrix(m[i]) * X_sym.row(i).T\n",
    "    for i in range(num_x)\n",
    "]).T\n",
    "\n",
    "F_sym_mx_sym = F_sym - mx_sym\n",
    "common_objectives_sym = []\n",
    "for i in range(num_x):\n",
    "    print('Constructing common objective for state {}.'.format(i + 1))\n",
    "    common_objectives_sym.append(\n",
    "        sp.expand(0.5 * F_sym_mx_sym.row(i) * sp.Matrix(Lambda[i]) * F_sym_mx_sym.row(i).T)\n",
    "    )\n",
    "    \n",
    "X_sym_mu = X_sym - sp.Matrix(mu)\n",
    "x_objectives_sym = []\n",
    "for i in range(num_x):\n",
    "    print('Constructing objective for state {}.'.format(i + 1))\n",
    "    x_objectives_sym.append(\n",
    "        sp.expand(0.5 * X_sym_mu.row(i) * sp.Matrix(inv_Sigma[i]) * X_sym_mu.row(i).T)\n",
    "    )\n",
    "    \n",
    "x_gradients_sym = []\n",
    "for i in range(num_x):\n",
    "    print('Constructing gradient for state {}.'.format(i + 1))    \n",
    "    syms = [\n",
    "        sym.jacobian(X_sym.row(i)) \n",
    "        for sym in common_objectives_sym\n",
    "    ]\n",
    "    syms.append(x_objectives_sym[i].jacobian(X_sym.row(i))) \n",
    "    x_gradients_sym.append(syms)\n",
    "    \n",
    "x_hessians_sym = []\n",
    "for i in range(num_x):\n",
    "    print('Constructing hessian for state {}.'.format(i + 1))\n",
    "    syms = [\n",
    "        sym.jacobian(X_sym.row(i))\n",
    "        for sym in x_gradients_sym[i]\n",
    "    ]\n",
    "    x_hessians_sym.append(syms) \n",
    "    \n",
    "theta_gradients_sym = []\n",
    "for i in range(num_x):\n",
    "    print('Constructing gradient for theta over state {}'.format(i + 1))\n",
    "    theta_gradients_sym.append(common_objectives_sym[i].jacobian(theta_sym))\n",
    "\n",
    "theta_hessians_sym = []\n",
    "for i in range(num_x):\n",
    "    print('Constructing hessian for theta over state {}'.format(i + 1))\n",
    "    theta_hessians_sym.append(theta_gradients_sym[i].jacobian(theta_sym))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    print('Constructing common objective functions.')\n",
    "    common_objectives_func = [\n",
    "        sp.lambdify((dynamical.dummy_x, dynamical.dummy_theta), sym, dummify=False, modules='numpy')\n",
    "        for sym in common_objectives_sym\n",
    "    ]\n",
    "\n",
    "    print('Constructing objetive functions for states.')\n",
    "    x_objectives_sym_func = [\n",
    "        sp.lambdify((dynamical.dummy_x, dynamical.dummy_theta), sym, dummify=False, modules='numpy')\n",
    "        for sym in x_objectives_sym\n",
    "    ]\n",
    "\n",
    "    print('Constructing gradient functions for states.')\n",
    "    x_gradients_sym_func = [\n",
    "        [\n",
    "            sp.lambdify((dynamical.dummy_x, dynamical.dummy_theta), sym, dummify=False, modules='numpy')\n",
    "            for sym in x_gradients_sym[i]\n",
    "        ]\n",
    "        for i in range(num_x)\n",
    "    ]\n",
    "\n",
    "    print('Constructing hessian functions for states.')\n",
    "    x_hessians_sym_func = [\n",
    "        [\n",
    "            sp.lambdify((dynamical.dummy_x, dynamical.dummy_theta), sym, dummify=False, modules='numpy')\n",
    "            for sym in x_hessians_sym[i]\n",
    "        ]\n",
    "        for i in range(num_x)\n",
    "    ]\n",
    "    \n",
    "    print('Constructing gradient functions for theta.')\n",
    "    theta_gradients_sym_func = [\n",
    "        sp.lambdify((dynamical.dummy_x, dynamical.dummy_theta), sym, dummify=False, modules='numpy')\n",
    "        for sym in theta_gradients_sym\n",
    "    ]\n",
    "    \n",
    "    print('Constructing hessian functions for theta.')\n",
    "    theta_hessians_sym_func = [\n",
    "        sp.lambdify((dynamical.dummy_x, dynamical.dummy_theta), sym, dummify=False, modules='numpy')\n",
    "        for sym in theta_hessians_sym\n",
    "    ]\n",
    "    \n",
    "    def x_objective_and_gradient_(x):\n",
    "        eta_X[i] = x\n",
    "        objective = x_objectives_sym_func[i](eta_X, eta_theta).ravel()[0]\n",
    "        for func in common_objectives_func:\n",
    "            objective += func(eta_X, eta_theta).ravel()[0]\n",
    "\n",
    "        gradient = np.zeros(num_est_t)\n",
    "        for func in x_gradients_sym_func[i]:\n",
    "            gradient += func(eta_X, eta_theta).ravel()\n",
    "        return objective, gradient\n",
    "\n",
    "    def x_hessian_(x):\n",
    "        hessian = np.zeros((num_est_t, num_est_t))\n",
    "        for func in x_hessians_sym_func[i]:\n",
    "            hessian += func(eta_X, eta_theta)\n",
    "        return hessian\n",
    "\n",
    "    def theta_objective_and_gradient_(theta):\n",
    "        eta_theta[:] = theta\n",
    "        objective = 0\n",
    "        for func in common_objectives_func:\n",
    "            objective += func(eta_X, theta).ravel()[0]\n",
    "\n",
    "        gradient = np.zeros(num_theta)\n",
    "        for func in theta_gradients_sym_func:\n",
    "            gradient += func(eta_X, theta).ravel()\n",
    "        return objective, gradient\n",
    "\n",
    "    def theta_hessian_(theta):\n",
    "        hessian = np.zeros((num_theta, num_theta))\n",
    "        for func in theta_hessians_sym_func:\n",
    "            hessian += func(eta_X, theta)\n",
    "        return hessian    \n",
    "except RecursionError as e:\n",
    "    raise RuntimeError('Unable to construct functions')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eta_X = mu.copy()\n",
    "Xi_X = Sigma.copy()\n",
    "eta_theta = np.zeros(num_theta)\n",
    "Xi_theta = np.zeros((num_theta, num_theta))\n",
    "\n",
    "figure, plotting_config = utils.create_estimation_figure(dynamical, delta)\n",
    "utils.add_sample_path(figure, plotting_config, spl_X, spl_tps)\n",
    "utils.add_observations(figure, plotting_config, obs_Y, obs_tps, delta)\n",
    "utils.add_gaussian_regression_result(figure, plotting_config, eta_X, est_tps)\n",
    "\n",
    "eta_theta_costs = []\n",
    "eta_X_costs = []\n",
    "\n",
    "for it in range(1, 1001):\n",
    "    result = optimize.minimize(fun=theta_objective_and_gradient_, x0=eta_theta, method='Newton-CG', \n",
    "                               jac=True, hess=theta_hessian_, options={'disp': False})\n",
    "#     eta_theta = np.abs(result.x)\n",
    "    eta_theta_cost = result.fun\n",
    "    eta_theta_costs.append(eta_theta_cost)\n",
    "    \n",
    "    eta_X_cost = 0\n",
    "    for i in range(num_x):\n",
    "        result = optimize.minimize(fun=x_objective_and_gradient_, x0=eta_X[i], method='Newton-CG', \n",
    "                                   jac=True, hess=x_hessian_, options={'disp': False})\n",
    "        eta_X_cost += result.fun\n",
    "    eta_X_costs.append(eta_X_cost)\n",
    "    \n",
    "    if it % 50 != 0:\n",
    "        print('.', end='')\n",
    "    else:\n",
    "        print('Iteration: {}, theta cost: {:.4f}, X cost: {:.4f}'.format(it, eta_theta_cost, eta_X_cost))\n",
    "        utils.add_estimation_step(figure, plotting_config, dynamical, eta_X, est_tps, theta, eta_theta)\n",
    "        \n",
    "for i in range(num_x):\n",
    "    x_objective_and_gradient_(eta_X[i])\n",
    "    Xi_X[i] = numericals.cholesky_inv(x_hessian_(eta_X[i]))\n",
    "    \n",
    "    theta_objective_and_gradient_(eta_theta)\n",
    "    Xi_theta = numericals.cholesky_inv(theta_hessian_(eta_theta))\n",
    "\n",
    "utils.add_estimation_result(figure, plotting_config, dynamical, eta_X, est_tps, theta, eta_theta)\n",
    "utils.plot_estimation_result(plotting_config, dynamical, spl_X, spl_tps, obs_Y, obs_tps, delta, eta_X, Xi_X,\n",
    "                             est_tps, theta, eta_theta, Xi_theta)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper to plot costs\n",
    "figure = plt.figure(figsize=plt.figaspect(0.4))\n",
    "ax = figure.add_subplot(1, 2, 1)\n",
    "ax.plot(eta_X_costs)\n",
    "ax.set_title('Cost for X')\n",
    "\n",
    "ax = figure.add_subplot(1, 2, 2)\n",
    "ax.plot(eta_X_costs)\n",
    "ax.set_title('Cost for theta')\n",
    "\n",
    "figure.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper to plot theta for protein signaling transduction\n",
    "figure = plt.figure()\n",
    "ax = plt.gca()\n",
    "bar_width = 0.3\n",
    "bar_indices = np.arange(theta.size - 1)\n",
    "ax.bar(bar_indices, theta[:-1], bar_width, color='C0', label='Truth')\n",
    "ax.bar(bar_indices + bar_width, eta_theta[:-1], bar_width, color='C2', label='Estimation',\n",
    "       yerr=2 * np.sqrt(np.diagonal(Xi_theta))[:-1],\n",
    "       error_kw=dict(ecolor='0.2', capsize=3., capthick=1.))\n",
    "ax.set_ylabel('Value')\n",
    "ax.set_title('Theta')\n",
    "ax.set_xticks(bar_indices + bar_width / 2)\n",
    "ax.set_xticklabels([r'${}$'.format(label) for label in dynamical.theta_labels])\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles=handles, labels=labels, loc=0)\n",
    "figure.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
